{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e7706215",
      "metadata": {
        "id": "e7706215"
      },
      "source": [
        "#  CrimeLens â€” Video to 3D Gaussian Splat Model\n",
        "\n",
        "Convert a short video into a `.ply` Gaussian Splat model viewable in the Unity VR Viewer.\n",
        "\n",
        "**Prerequisites**: Runtime â†’ Change runtime type â†’ **GPU (G4 is preffered).**\n",
        "\n",
        "Run cells **top to bottom**. Each section has its own Gradio UI for parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "66729c6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66729c6c",
        "outputId": "d507a793-ec41-46af-b306-a0f2338980ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ GPU: NVIDIA RTX PRO 6000 Blackwell Server Edition, 97887 MiB\n",
            "âœ“ CUDA available: True\n",
            "âœ“ PyTorch: 2.10.0+cu128\n",
            "âœ“ Python: 3.12.12\n"
          ]
        }
      ],
      "source": [
        "# â”€â”€ 0. Verify GPU â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import subprocess, sys\n",
        "\n",
        "result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'],\n",
        "                        capture_output=True, text=True)\n",
        "if result.returncode != 0:\n",
        "    print('âš   No NVIDIA GPU detected!  Runtime â†’ Change runtime type â†’ T4 GPU')\n",
        "    sys.exit('Please enable GPU and re-run.')\n",
        "else:\n",
        "    print('âœ“ GPU:', result.stdout.strip())\n",
        "\n",
        "import torch\n",
        "print('âœ“ CUDA available:', torch.cuda.is_available())\n",
        "print('âœ“ PyTorch:', torch.__version__)\n",
        "print('âœ“ Python:', sys.version.split()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f24df6aa",
      "metadata": {
        "id": "f24df6aa"
      },
      "source": [
        "## Section 1 â€” Environment Setup\n",
        "Installs COLMAP, clones gaussian-splatting, builds CUDA extensions. **~5 min** first run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1255ca1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1255ca1e",
        "outputId": "a4b6d02e-dc9c-4207-c976-458886b57f8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing COLMAP...\n",
            "$ apt-get install -qq -y colmap\n",
            "âœ“ COLMAP: ERROR: Command `--version` not recognized. To list the available commands, run `colmap help`.\n",
            "Installing Xvfb...\n",
            "$ apt-get install -qq -y xvfb\n",
            "âœ“ Xvfb installed\n",
            "âœ“ FFmpeg: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "Cloning gaussian-splatting...\n",
            "$ git clone --recursive https://github.com/graphdeco-inria/gaussian-splatting /content/gaussian-splatting\n",
            "Building diff-gaussian-rasterization (CUDA extension)...\n",
            "$ pip install -q /content/gaussian-splatting/submodules/diff-gaussian-rasterization\n",
            "Building simple-knn...\n",
            "$ pip install -q /content/gaussian-splatting/submodules/simple-knn\n",
            "Installing Python packages...\n",
            "$ pip install -q gradio plotly plyfile tqdm imageio imageio-ffmpeg rich lpips\n",
            "\n",
            "âœ… Environment ready!\n"
          ]
        }
      ],
      "source": [
        "# â”€â”€ 1. Install system & Python dependencies â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import os, subprocess, sys\n",
        "from pathlib import Path\n",
        "\n",
        "WORKSPACE = Path('/content/vid2splat')\n",
        "WORKSPACE.mkdir(exist_ok=True)\n",
        "GS_REPO   = Path('/content/gaussian-splatting')\n",
        "\n",
        "def sh(cmd, **kwargs):\n",
        "    \"\"\"Run a shell command and stream output.\"\"\"\n",
        "    print(f'$ {cmd}')\n",
        "    r = subprocess.run(cmd, shell=True, text=True, **kwargs)\n",
        "    if r.returncode != 0:\n",
        "        raise RuntimeError(f'Command failed (exit {r.returncode}): {cmd}')\n",
        "    return r\n",
        "\n",
        "# â”€â”€ COLMAP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print('Installing COLMAP...')\n",
        "sh('apt-get install -qq -y colmap')\n",
        "r = subprocess.run(['colmap', '--version'], capture_output=True, text=True)\n",
        "print('âœ“ COLMAP:', r.stdout.strip() or r.stderr.strip())\n",
        "\n",
        "# â”€â”€ Xvfb (virtual display â€” needed for COLMAP GPU/OpenGL on headless Colab) â”€â”€\n",
        "print('Installing Xvfb...')\n",
        "sh('apt-get install -qq -y xvfb')\n",
        "print('âœ“ Xvfb installed')\n",
        "\n",
        "# â”€â”€ FFmpeg (usually pre-installed) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "r = subprocess.run(['ffmpeg', '-version'], capture_output=True, text=True)\n",
        "print('âœ“ FFmpeg:', r.stdout.split('\\n')[0])\n",
        "\n",
        "# â”€â”€ Gaussian Splatting repo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "if not GS_REPO.exists():\n",
        "    print('Cloning gaussian-splatting...')\n",
        "    sh('git clone --recursive https://github.com/graphdeco-inria/gaussian-splatting /content/gaussian-splatting')\n",
        "else:\n",
        "    print('âœ“ gaussian-splatting already cloned')\n",
        "\n",
        "# â”€â”€ Build CUDA extensions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print('Building diff-gaussian-rasterization (CUDA extension)...')\n",
        "sh('pip install -q /content/gaussian-splatting/submodules/diff-gaussian-rasterization')\n",
        "print('Building simple-knn...')\n",
        "sh('pip install -q /content/gaussian-splatting/submodules/simple-knn')\n",
        "\n",
        "# â”€â”€ Python packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print('Installing Python packages...')\n",
        "sh('pip install -q gradio plotly plyfile tqdm imageio imageio-ffmpeg rich lpips')\n",
        "\n",
        "print('\\nâœ… Environment ready!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5824ea3",
      "metadata": {
        "id": "f5824ea3"
      },
      "source": [
        "## Section 2 â€” Video Upload & Project Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a87f243d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "collapsed": true,
        "id": "a87f243d",
        "outputId": "00411c65-11e1-46b5-cf09-52c1e9b1e09b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://315f2804e217dd57f2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://315f2804e217dd57f2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# â”€â”€ 2. Upload video or mount Google Drive â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import gradio as gr\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "WORKSPACE = Path('/content/vid2splat')\n",
        "state = {}  # shared pipeline state\n",
        "\n",
        "def setup_project(video_file, project_name, use_drive, drive_path):\n",
        "    if not project_name.strip():\n",
        "        return 'âš  Enter a project name.', gr.update()\n",
        "\n",
        "    proj_dir = WORKSPACE / project_name.strip().replace(' ', '_')\n",
        "    input_dir = proj_dir / 'input'\n",
        "    input_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if use_drive and drive_path.strip():\n",
        "        # Mount Google Drive\n",
        "        from google.colab import drive\n",
        "        drive.mount('/content/drive')\n",
        "        src = Path(drive_path.strip())\n",
        "        if not src.exists():\n",
        "            return f'âš  Drive path not found: {src}', gr.update()\n",
        "        video_dest = proj_dir / src.name\n",
        "        shutil.copy2(src, video_dest)\n",
        "        state['video_path'] = str(video_dest)\n",
        "    elif video_file is not None:\n",
        "        video_dest = proj_dir / Path(video_file.name).name\n",
        "        shutil.copy2(video_file.name, video_dest)\n",
        "        state['video_path'] = str(video_dest)\n",
        "    else:\n",
        "        return 'âš  Upload a video or provide a Drive path.', gr.update()\n",
        "\n",
        "    state['project_dir'] = str(proj_dir)\n",
        "    state['project_name'] = project_name.strip()\n",
        "    sz = Path(state['video_path']).stat().st_size / 1024**2\n",
        "    return f'âœ… Project \"{project_name}\" ready.  Video: {Path(state[\"video_path\"]).name} ({sz:.1f} MB)', gr.update(value=str(proj_dir))\n",
        "\n",
        "with gr.Blocks(title='Vid2Splat â€” Upload') as upload_ui:\n",
        "    gr.Markdown('### ğŸ“‚ Upload Video')\n",
        "    with gr.Row():\n",
        "        proj_name  = gr.Textbox(label='Project name', placeholder='my_scene', value='my_scene')\n",
        "        proj_dir_display = gr.Textbox(label='Project directory', interactive=False)\n",
        "    video_input = gr.File(label='Upload video (.mp4 / .mov / .avi / .mkv)', file_types=['video'])\n",
        "    with gr.Accordion('Google Drive (large files)', open=False):\n",
        "        use_drive  = gr.Checkbox(label='Use Google Drive instead', value=False)\n",
        "        drive_path = gr.Textbox(label='Drive path', placeholder='/content/drive/MyDrive/video.mp4')\n",
        "    setup_btn  = gr.Button('Set up project', variant='primary')\n",
        "    status_out = gr.Markdown()\n",
        "    setup_btn.click(setup_project,\n",
        "                    inputs=[video_input, proj_name, use_drive, drive_path],\n",
        "                    outputs=[status_out, proj_dir_display])\n",
        "\n",
        "upload_ui.launch(debug=False, share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0dc54086",
      "metadata": {
        "id": "0dc54086"
      },
      "source": [
        "## Section 3 â€” Frame Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3c9953de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "3c9953de",
        "outputId": "86aa9c7d-0b71-48a8-8664-f76ae269ddc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://0cda697add6d672c1c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://0cda697add6d672c1c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# â”€â”€ 3. Extract frames with FFmpeg â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import gradio as gr\n",
        "import subprocess, json\n",
        "from pathlib import Path\n",
        "import PIL.Image\n",
        "\n",
        "PRESET_FRAME_TARGETS = {'Quick Preview': 60, 'Balanced': 120, 'High Quality': 250}\n",
        "\n",
        "\n",
        "def get_video_info(video_path):\n",
        "    cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_streams', video_path]\n",
        "    r = subprocess.run(cmd, capture_output=True, text=True)\n",
        "    data = json.loads(r.stdout)\n",
        "    for s in data.get('streams', []):\n",
        "        if s.get('codec_type') == 'video':\n",
        "            dur = float(s.get('duration', 0) or data.get('format', {}).get('duration', 0))\n",
        "            num, den = map(int, s.get('r_frame_rate', '30/1').split('/'))\n",
        "            return dur, (num / den if den else 30.0)\n",
        "    return 0.0, 30.0\n",
        "\n",
        "\n",
        "def extract_frames(preset, target_frames, max_frames, scale_pct):\n",
        "    video_path = state.get('video_path')\n",
        "    proj_dir   = Path(state.get('project_dir', '/content/vid2splat/scene'))\n",
        "    if not video_path or not Path(video_path).exists():\n",
        "        return 'âš  Run Section 2 first.', []\n",
        "\n",
        "    input_dir = proj_dir / 'input'\n",
        "    input_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Clear old frames\n",
        "    for f in input_dir.glob('*.jpg'):\n",
        "        f.unlink()\n",
        "\n",
        "    if preset != 'Custom':\n",
        "        target_frames = PRESET_FRAME_TARGETS[preset]\n",
        "\n",
        "    target_frames = min(int(target_frames), int(max_frames))\n",
        "    scale = scale_pct / 100.0\n",
        "\n",
        "    duration, native_fps = get_video_info(video_path)\n",
        "    fps = min(target_frames / max(duration, 1), native_fps)\n",
        "\n",
        "    vf = f'fps={fps:.4f}'\n",
        "    if scale < 1.0:\n",
        "        vf += f',scale=iw*{scale:.2f}:ih*{scale:.2f}'\n",
        "\n",
        "    cmd = ['ffmpeg', '-y', '-i', video_path,\n",
        "           '-qscale:v', '1', '-qmin', '1',\n",
        "           '-vf', vf,\n",
        "           str(input_dir / '%04d.jpg')]\n",
        "    r = subprocess.run(cmd, capture_output=True, text=True)\n",
        "\n",
        "    frames = sorted(input_dir.glob('*.jpg'))\n",
        "    n = len(frames)\n",
        "    state['n_frames'] = n\n",
        "    state['input_dir'] = str(input_dir)\n",
        "\n",
        "    if n == 0:\n",
        "        return f'âš  FFmpeg error:\\n{r.stderr[-1000:]}', []\n",
        "\n",
        "    # Sample thumbnails (every Nth)\n",
        "    step = max(1, n // 8)\n",
        "    thumbs = [str(f) for f in frames[::step]][:8]\n",
        "\n",
        "    msg = (f'âœ… Extracted **{n} frames** at {fps:.2f} fps  '\n",
        "           f'| source duration {duration:.1f}s  '\n",
        "           f'| est. COLMAP time ~{max(1, n // 60)} min')\n",
        "    if n < 30:\n",
        "        msg += '\\nâš  Very few frames â€” quality may be low.'\n",
        "    return msg, thumbs\n",
        "\n",
        "\n",
        "with gr.Blocks(title='Vid2Splat â€” Frames') as frames_ui:\n",
        "    gr.Markdown('### ğŸ Frame Extraction')\n",
        "    with gr.Row():\n",
        "        preset_dd  = gr.Dropdown(['Quick Preview', 'Balanced', 'High Quality', 'Custom'],\n",
        "                                  label='Preset', value='Balanced')\n",
        "        target_sl  = gr.Slider(20, 9000, value=120, step=10, label='Target frames (Custom only)')\n",
        "        max_sl     = gr.Slider(50, 9000, value=150, step=10, label='Max frames')\n",
        "        scale_sl   = gr.Slider(25, 100, value=100, step=25, label='Image scale %')\n",
        "    extract_btn = gr.Button('Extract frames', variant='primary')\n",
        "    status_out  = gr.Markdown()\n",
        "    gallery     = gr.Gallery(label='Sample frames', columns=4, height='auto')\n",
        "    extract_btn.click(extract_frames,\n",
        "                      inputs=[preset_dd, target_sl, max_sl, scale_sl],\n",
        "                      outputs=[status_out, gallery])\n",
        "\n",
        "frames_ui.launch(debug=False, share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fb604b1",
      "metadata": {
        "id": "7fb604b1"
      },
      "source": [
        "## Section 4 â€” COLMAP Structure-from-Motion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d76c0eb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "d76c0eb7",
        "outputId": "68a34b5a-8b6c-439d-dd75-fdd515d72395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Matching image [2/60] in 1.116s\n",
            "* Running on public URL: https://d4ee5a9906801d3069.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://d4ee5a9906801d3069.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# â”€â”€ 4. COLMAP SfM â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import gradio as gr\n",
        "import subprocess, struct, os, sys, time, traceback, tempfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Per-step timeouts (seconds)\n",
        "TIMEOUT_EXTRACT = 3600   # 60 min\n",
        "TIMEOUT_MATCH   = 7200   # 120 min  â€” slowest step\n",
        "TIMEOUT_MAPPER  = 3600   # 60 min\n",
        "\n",
        "\n",
        "def count_registered_images(sparse_0: Path) -> int:\n",
        "    images_bin = sparse_0 / 'images.bin'\n",
        "    if images_bin.exists():\n",
        "        with open(images_bin, 'rb') as f:\n",
        "            data = f.read(8)\n",
        "        if len(data) == 8:\n",
        "            return struct.unpack('<Q', data)[0]\n",
        "    images_txt = sparse_0 / 'images.txt'\n",
        "    if images_txt.exists():\n",
        "        with open(images_txt) as f:\n",
        "            lines = [l for l in f if l.strip() and not l.startswith('#')]\n",
        "        return len(lines) // 2\n",
        "    return 0\n",
        "\n",
        "\n",
        "def run_colmap(preset, matcher, overlap, use_gpu_chk):\n",
        "    \"\"\"\n",
        "    Generator â€” yields live markdown status as COLMAP runs.\n",
        "    Gradio 4.x streams yielded values directly to the UI component.\n",
        "    \"\"\"\n",
        "    xvfb_proc  = None\n",
        "    all_log    = []\n",
        "    step_log   = []\n",
        "    t0         = time.time()\n",
        "    _n_frames  = 0\n",
        "    _matcher   = matcher\n",
        "\n",
        "    def elapsed():\n",
        "        return '{:.0f}s'.format(time.time() - t0)\n",
        "\n",
        "    def tail(n=30):\n",
        "        lines = step_log[-n:] if step_log else []\n",
        "        return '\\n'.join(lines) if lines else '(waitingâ€¦)'\n",
        "\n",
        "    def render(emoji, step_name, note=''):\n",
        "        return (\n",
        "            '**COLMAP** | {elapsed} elapsed | {n} images | GPU={gpu} | matcher={m}\\n\\n'\n",
        "            '---\\n'\n",
        "            '{e} **{step}**{note}\\n'\n",
        "            '```\\n{log}\\n```'\n",
        "        ).format(\n",
        "            elapsed=elapsed(), n=_n_frames, gpu=use_gpu_chk,\n",
        "            m=_matcher, e=emoji, step=step_name,\n",
        "            note=' â€” ' + note if note else '',\n",
        "            log=tail(),\n",
        "        )\n",
        "\n",
        "    yield 'â³ Initializing COLMAPâ€¦'\n",
        "\n",
        "    try:\n",
        "        _state = sys.modules['__main__'].__dict__.get('state') or globals().get('state')\n",
        "        if _state is None:\n",
        "            yield 'âŒ `state` not found â€” re-run Section 2 first.'\n",
        "            return\n",
        "\n",
        "        proj_dir_str = _state.get('project_dir')\n",
        "        if not proj_dir_str:\n",
        "            yield 'âŒ No project directory â€” complete Section 2 first.'\n",
        "            return\n",
        "\n",
        "        proj_dir  = Path(proj_dir_str)\n",
        "        input_dir = proj_dir / 'input'\n",
        "        if not input_dir.exists():\n",
        "            yield 'âŒ Input directory not found: `{}` â€” run Section 3 first.'.format(input_dir)\n",
        "            return\n",
        "\n",
        "        frames = list(input_dir.glob('*.jpg')) + list(input_dir.glob('*.png'))\n",
        "        if not frames:\n",
        "            yield 'âŒ No images found in `{}` â€” run Section 3 first.'.format(input_dir)\n",
        "            return\n",
        "\n",
        "        _n_frames = len(frames)\n",
        "\n",
        "        db_path = proj_dir / 'database.db'\n",
        "        sparse  = proj_dir / 'sparse'\n",
        "        sparse.mkdir(exist_ok=True)\n",
        "\n",
        "        for stale in [db_path, db_path.with_suffix('.db-wal'), db_path.with_suffix('.db-shm')]:\n",
        "            if stale.exists():\n",
        "                stale.unlink()\n",
        "                print('[COLMAP] Removed stale file: {}'.format(stale.name))\n",
        "\n",
        "        if preset != 'Custom':\n",
        "            _matcher = 'exhaustive' if preset == 'High Quality' else 'sequential'\n",
        "            overlap  = 15 if preset == 'Balanced' else 10\n",
        "        else:\n",
        "            _matcher = matcher\n",
        "\n",
        "        gpu_flag = '1' if use_gpu_chk else '0'\n",
        "\n",
        "        if not use_gpu_chk and _n_frames > 80:\n",
        "            yield (\n",
        "                'âš  **CPU SIFT with {} frames â‰ˆ {:.0f} hours** (~90 s/pair Ã— {} pairs).\\n\\n'\n",
        "                '**Options:**\\n'\n",
        "                '- Re-run Section 3 with **Quick Preview** (60 frames), then retry\\n'\n",
        "                '- Tick **Use GPU** above (requires Xvfb but is ~50Ã— faster)'\n",
        "            ).format(_n_frames, _n_frames * 15 * 90 / 3600, _n_frames * 15)\n",
        "            return\n",
        "\n",
        "        colmap_env = {**os.environ, 'QT_QPA_PLATFORM': 'offscreen'}\n",
        "\n",
        "        # â”€â”€ Xvfb start / restart helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        def start_xvfb():\n",
        "            nonlocal xvfb_proc\n",
        "            display = ':99'\n",
        "            subprocess.run(['pkill', '-f', 'Xvfb {}'.format(display)], capture_output=True)\n",
        "            time.sleep(0.5)\n",
        "            for lp in ['/tmp/.X99-lock', '/tmp/.X11-unix/X99']:\n",
        "                try:\n",
        "                    os.remove(lp)\n",
        "                except FileNotFoundError:\n",
        "                    pass\n",
        "            xvfb_proc = subprocess.Popen(\n",
        "                ['Xvfb', display, '-screen', '0', '1024x768x24',\n",
        "                 '-nolisten', 'tcp', '-ac'],\n",
        "                stdout=subprocess.DEVNULL,\n",
        "                stderr=subprocess.DEVNULL,\n",
        "            )\n",
        "            time.sleep(1.5)\n",
        "            if xvfb_proc.poll() is not None:\n",
        "                return False, xvfb_proc.returncode\n",
        "            print('[COLMAP] Xvfb running on {} (pid={})'.format(display, xvfb_proc.pid))\n",
        "            colmap_env['DISPLAY'] = display\n",
        "            return True, 0\n",
        "\n",
        "        def ensure_xvfb(step_label):\n",
        "            if not use_gpu_chk:\n",
        "                return True\n",
        "            if xvfb_proc is not None and xvfb_proc.poll() is None:\n",
        "                return True\n",
        "            print('[COLMAP] Xvfb exited before {} â€” restartingâ€¦'.format(step_label))\n",
        "            ok, _ = start_xvfb()\n",
        "            return ok\n",
        "\n",
        "        if use_gpu_chk:\n",
        "            yield 'â³ Starting Xvfb virtual displayâ€¦'\n",
        "            ok, rc = start_xvfb()\n",
        "            if not ok:\n",
        "                yield 'âŒ **Xvfb failed to start** (exit {}).\\nUncheck **Use GPU** to use CPU SIFT.'.format(rc)\n",
        "                return\n",
        "\n",
        "        sys.stdout.flush()\n",
        "\n",
        "        # â”€â”€ streaming step runner â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        def stream_step(label, cmd, timeout_s):\n",
        "            nonlocal step_log\n",
        "            step_log = []\n",
        "            cmd_str  = ' '.join(str(c) for c in cmd)\n",
        "            print('\\n[COLMAP] {}\\n[CMD] {}'.format(label, cmd_str))\n",
        "            sys.stdout.flush()\n",
        "\n",
        "            try:\n",
        "                proc = subprocess.Popen(\n",
        "                    cmd,\n",
        "                    stdout=subprocess.PIPE,\n",
        "                    stderr=subprocess.STDOUT,\n",
        "                    text=True,\n",
        "                    env=colmap_env,\n",
        "                )\n",
        "            except FileNotFoundError as e:\n",
        "                yield render('âŒ', label, 'command not found: `{}`'.format(e))\n",
        "                yield (False, -1)\n",
        "                return\n",
        "\n",
        "            deadline     = time.time() + timeout_s\n",
        "            last_yield_t = time.time()\n",
        "\n",
        "            for raw_line in proc.stdout:\n",
        "                line = raw_line.rstrip()\n",
        "                step_log.append(line)\n",
        "                all_log.append(line)\n",
        "                print(line)\n",
        "                sys.stdout.flush()\n",
        "\n",
        "                if time.time() > deadline:\n",
        "                    proc.kill()\n",
        "                    proc.wait()\n",
        "                    tmsg = 'timed out after {:.0f} min'.format(timeout_s / 60)\n",
        "                    print('[COLMAP] TIMEOUT â€” {}'.format(label))\n",
        "                    yield render('âŒ', label, tmsg)\n",
        "                    yield (False, -1)\n",
        "                    return\n",
        "\n",
        "                now = time.time()\n",
        "                important = any(kw in line.lower() for kw in\n",
        "                                ('processed file', 'matching image', 'registering',\n",
        "                                 'error', 'warning', 'failed', 'adding image'))\n",
        "                if now - last_yield_t >= 2.0 or important:\n",
        "                    yield render('â³', label)\n",
        "                    last_yield_t = now\n",
        "\n",
        "            proc.wait()\n",
        "            rc = proc.returncode\n",
        "            print('[COLMAP] {} exit code: {}'.format(label, rc))\n",
        "            sys.stdout.flush()\n",
        "\n",
        "            if rc != 0:\n",
        "                yield render('âŒ', label, 'exit code `{}`'.format(rc))\n",
        "                yield (False, rc)\n",
        "            else:\n",
        "                yield render('âœ…', label, 'done')\n",
        "                yield (True, 0)\n",
        "\n",
        "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        # Step 1 â€” Feature extraction\n",
        "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        ok = False\n",
        "        rc = -1\n",
        "        for item in stream_step('Feature extraction', [\n",
        "            'colmap', 'feature_extractor',\n",
        "            '--database_path',             str(db_path),\n",
        "            '--image_path',                str(input_dir),\n",
        "            '--ImageReader.single_camera', '1',\n",
        "            '--SiftExtraction.use_gpu',    gpu_flag,\n",
        "        ], TIMEOUT_EXTRACT):\n",
        "            if isinstance(item, tuple):\n",
        "                ok, rc = item\n",
        "            else:\n",
        "                yield item\n",
        "        if not ok:\n",
        "            return\n",
        "\n",
        "        step_log = []\n",
        "\n",
        "        if not ensure_xvfb('Sequential matching'):\n",
        "            yield 'âŒ Could not restart Xvfb before matching.  Uncheck **Use GPU** and retry.'\n",
        "            return\n",
        "        yield render('â³', 'Starting {} matchingâ€¦'.format(_matcher))\n",
        "\n",
        "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        # Step 2 â€” Matching\n",
        "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        if _matcher == 'sequential':\n",
        "            match_cmd = [\n",
        "                'colmap', 'sequential_matcher',\n",
        "                '--database_path',              str(db_path),\n",
        "                '--SiftMatching.use_gpu',        gpu_flag,\n",
        "                '--SequentialMatching.overlap',  str(int(overlap)),\n",
        "            ]\n",
        "        else:\n",
        "            match_cmd = [\n",
        "                'colmap', 'exhaustive_matcher',\n",
        "                '--database_path',        str(db_path),\n",
        "                '--SiftMatching.use_gpu', gpu_flag,\n",
        "            ]\n",
        "\n",
        "        ok = False\n",
        "        for item in stream_step('{} matching'.format(_matcher.capitalize()),\n",
        "                                 match_cmd, TIMEOUT_MATCH):\n",
        "            if isinstance(item, tuple):\n",
        "                ok, rc = item\n",
        "            else:\n",
        "                yield item\n",
        "        if not ok:\n",
        "            return\n",
        "\n",
        "        step_log = []\n",
        "\n",
        "        if not ensure_xvfb('Mapper'):\n",
        "            yield 'âŒ Could not restart Xvfb before mapper.  Uncheck **Use GPU** and retry.'\n",
        "            return\n",
        "\n",
        "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        # Step 3 â€” Mapper\n",
        "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        ok = False\n",
        "        for item in stream_step('Mapper (sparse reconstruction)', [\n",
        "            'colmap', 'mapper',\n",
        "            '--database_path', str(db_path),\n",
        "            '--image_path',    str(input_dir),\n",
        "            '--output_path',   str(sparse),\n",
        "        ], TIMEOUT_MAPPER):\n",
        "            if isinstance(item, tuple):\n",
        "                ok, rc = item\n",
        "            else:\n",
        "                yield item\n",
        "        if not ok:\n",
        "            return\n",
        "\n",
        "        step_log = []\n",
        "\n",
        "        if not ensure_xvfb('Image undistortion'):\n",
        "            yield 'âŒ Could not restart Xvfb before undistortion.  Uncheck **Use GPU** and retry.'\n",
        "            return\n",
        "\n",
        "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        # Step 4 â€” Image undistortion\n",
        "        # Converts distorted camera model â†’ PINHOLE, required by train.py.\n",
        "        # image_undistorter --output_type COLMAP writes sparse files flat\n",
        "        # into dense/sparse/; train.py expects dense/sparse/0/ â€” so we\n",
        "        # move the files into a 0/ subdirectory after undistortion.\n",
        "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        dense_dir = proj_dir / 'dense'\n",
        "        dense_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        ok = False\n",
        "        for item in stream_step('Image undistortion', [\n",
        "            'colmap', 'image_undistorter',\n",
        "            '--image_path',  str(input_dir),\n",
        "            '--input_path',  str(sparse / '0'),\n",
        "            '--output_path', str(dense_dir),\n",
        "            '--output_type', 'COLMAP',\n",
        "        ], TIMEOUT_MAPPER):\n",
        "            if isinstance(item, tuple):\n",
        "                ok, rc = item\n",
        "            else:\n",
        "                yield item\n",
        "        if not ok:\n",
        "            return\n",
        "\n",
        "        # Move flat sparse/ files into sparse/0/ to match train.py's expected layout\n",
        "        sparse_flat = dense_dir / 'sparse'\n",
        "        sparse_sub  = sparse_flat / '0'\n",
        "        sparse_sub.mkdir(exist_ok=True)\n",
        "        moved = []\n",
        "        for f in list(sparse_flat.iterdir()):\n",
        "            if f.is_file():\n",
        "                f.rename(sparse_sub / f.name)\n",
        "                moved.append(f.name)\n",
        "        if moved:\n",
        "            print('[COLMAP] Moved sparse files to sparse/0/: {}'.format(', '.join(moved)))\n",
        "\n",
        "        # Point state to the undistorted dataset; train.py reads images from\n",
        "        # dense/images/ and sparse from dense/sparse/0/ automatically.\n",
        "        _state['project_dir'] = str(dense_dir)\n",
        "        print('[COLMAP] project_dir updated to undistorted dataset: {}'.format(dense_dir))\n",
        "\n",
        "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        # Validate output\n",
        "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        sparse_0   = sparse_sub   # dense/sparse/0/\n",
        "        registered = count_registered_images(sparse_0)\n",
        "        rate       = registered / _n_frames if _n_frames else 0.0\n",
        "        _state['sparse_dir'] = str(sparse_0)\n",
        "\n",
        "        if rate < 0.5:\n",
        "            verdict = 'âš  Low registration: {}/{} ({:.0f}%) â€” try exhaustive matcher or more frames.'.format(\n",
        "                registered, _n_frames, rate * 100)\n",
        "        elif rate < 0.8:\n",
        "            verdict = 'âš  Moderate: {}/{} ({:.0f}%)'.format(registered, _n_frames, rate * 100)\n",
        "        else:\n",
        "            verdict = 'âœ… COLMAP complete â€” {}/{} images registered ({:.0f}%)'.format(\n",
        "                registered, _n_frames, rate * 100)\n",
        "\n",
        "        print('[COLMAP] {}'.format(verdict))\n",
        "        yield (\n",
        "            '**COLMAP finished** in {elapsed}\\n\\n---\\n\\n### {verdict}\\n\\n'\n",
        "            '**Full log** (last 40 lines):\\n```\\n{log}\\n```'\n",
        "        ).format(elapsed=elapsed(), verdict=verdict, log='\\n'.join(all_log[-40:]))\n",
        "\n",
        "    except Exception:\n",
        "        tb = traceback.format_exc()\n",
        "        print('[run_colmap FATAL]\\n{}'.format(tb))\n",
        "        sys.stdout.flush()\n",
        "        yield '### âŒ Fatal error\\n```\\n{}\\n```'.format(tb)\n",
        "\n",
        "    finally:\n",
        "        if xvfb_proc is not None:\n",
        "            try:\n",
        "                xvfb_proc.terminate()\n",
        "                xvfb_proc.wait()\n",
        "            except Exception:\n",
        "                pass\n",
        "            print('[COLMAP] Xvfb stopped.')\n",
        "\n",
        "\n",
        "with gr.Blocks(title='Vid2Splat â€” COLMAP') as colmap_ui:\n",
        "    gr.Markdown(\n",
        "        '### ğŸ—‚ COLMAP Structure-from-Motion\\n'\n",
        "        '> Output updates **live** every ~2 seconds. '\n",
        "        'Raw logs also appear in the **Colab cell output** below.\\n\\n'\n",
        "        '> Timeouts: extraction 60 min Â· matching **120 min** Â· mapper 60 min Â· undistortion 60 min'\n",
        "    )\n",
        "    with gr.Row():\n",
        "        c_preset  = gr.Dropdown(['Quick Preview', 'Balanced', 'High Quality', 'Custom'],\n",
        "                                 label='Preset', value='Balanced')\n",
        "        c_matcher = gr.Dropdown(['sequential', 'exhaustive'], label='Matcher (Custom)', value='sequential')\n",
        "        c_overlap = gr.Slider(5, 30, value=15, step=5, label='Sequential overlap (Custom)')\n",
        "        c_gpu     = gr.Checkbox(label='Use GPU (CUDA SIFT â€” requires Xvfb)', value=False)\n",
        "    colmap_btn = gr.Button('Run COLMAP', variant='primary')\n",
        "    c_status   = gr.Markdown(value='*Press \"Run COLMAP\" to start.*')\n",
        "    colmap_btn.click(run_colmap,\n",
        "                     inputs=[c_preset, c_matcher, c_overlap, c_gpu],\n",
        "                     outputs=[c_status])\n",
        "\n",
        "colmap_ui.launch(debug=False, share=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bca6702",
      "metadata": {
        "id": "5bca6702"
      },
      "source": [
        "## Section 5 â€” 3D Gaussian Splatting Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "99efaf4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "99efaf4b",
        "outputId": "1416c68a-fe98-4671-900d-9b76a511da4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://a8702f37cfd432aa72.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://a8702f37cfd432aa72.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# â”€â”€ 5. Gaussian Splatting Training â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import gradio as gr\n",
        "import subprocess, threading, re, time, sys, traceback\n",
        "from pathlib import Path\n",
        "\n",
        "GS_REPO = Path('/content/gaussian-splatting')\n",
        "PRESET_ITERS = {'Quick Preview': 7000, 'Balanced': 15000, 'High Quality': 30000}\n",
        "PRESET_RES   = {'Quick Preview': 4,    'Balanced': 2,     'High Quality': 1}\n",
        "\n",
        "training_proc = None\n",
        "training_log  = []\n",
        "\n",
        "\n",
        "def start_training(preset, iterations, resolution, adv_visible,\n",
        "                   dens_until, dens_interval, lr_init, lr_final,\n",
        "                   opacity_lr, scaling_lr, lambda_dssim):\n",
        "    global training_proc, training_log\n",
        "\n",
        "    try:\n",
        "        _state = sys.modules['__main__'].__dict__.get('state') or globals().get('state')\n",
        "        if not _state:\n",
        "            return 'âŒ `state` not found â€” re-run Section 2 first.', gr.update()\n",
        "\n",
        "        # project_dir is updated to dense/ after undistortion in Section 4\n",
        "        proj_dir = Path(_state.get('project_dir', '/content/vid2splat/scene'))\n",
        "        output   = proj_dir.parent / (proj_dir.name + '_output')\n",
        "        output.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # After undistortion + move: sparse lives at proj_dir/sparse/0/\n",
        "        sparse_0 = proj_dir / 'sparse' / '0'\n",
        "        if not sparse_0.exists():\n",
        "            return (\n",
        "                'âš  Run Section 4 (COLMAP) first â€” `{}` not found.'.format(sparse_0),\n",
        "                gr.update()\n",
        "            )\n",
        "\n",
        "        if preset != 'Custom':\n",
        "            iterations = PRESET_ITERS[preset]\n",
        "            resolution = PRESET_RES[preset]\n",
        "            dens_until = int(iterations * 0.8)\n",
        "\n",
        "        # sh_degree is ALWAYS 3 â€” required by the Unity VR Viewer\n",
        "        sh_degree = 3\n",
        "\n",
        "        cmd = [\n",
        "            'python', str(GS_REPO / 'train.py'),\n",
        "            '--source_path',            str(proj_dir),\n",
        "            '--model_path',             str(output),\n",
        "            '--iterations',             str(int(iterations)),\n",
        "            '--sh_degree',              str(sh_degree),\n",
        "            '--resolution',             str(int(resolution)),\n",
        "            '--densify_until_iter',     str(int(dens_until)),\n",
        "            '--densification_interval', str(int(dens_interval)),\n",
        "            '--position_lr_init',       str(lr_init),\n",
        "            '--position_lr_final',      str(lr_final),\n",
        "            '--opacity_lr',             str(opacity_lr),\n",
        "            '--scaling_lr',             str(scaling_lr),\n",
        "            '--lambda_dssim',           str(lambda_dssim),\n",
        "        ]\n",
        "\n",
        "        training_log = []\n",
        "        _state['output_dir'] = str(output)\n",
        "        _state['training_iterations'] = int(iterations)\n",
        "\n",
        "        print(f'[TRAIN] source_path: {proj_dir}')\n",
        "        print(f'[TRAIN] sparse check: {sparse_0}  exists={sparse_0.exists()}')\n",
        "        print(f'[TRAIN] cmd: {\" \".join(cmd)}')\n",
        "        sys.stdout.flush()\n",
        "\n",
        "        training_proc = subprocess.Popen(\n",
        "            cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "\n",
        "        def stream():\n",
        "            for line in training_proc.stdout:\n",
        "                training_log.append(line.rstrip())\n",
        "            training_proc.wait()\n",
        "            print(f'[TRAIN] process exited with code {training_proc.returncode}')\n",
        "\n",
        "        threading.Thread(target=stream, daemon=True).start()\n",
        "        return f'ğŸš€ Training started ({int(iterations):,} iters, sh_degree=3, resolution=1/{int(resolution)})', gr.update()\n",
        "\n",
        "    except Exception:\n",
        "        tb = traceback.format_exc()\n",
        "        print(f'[TRAIN ERROR]\\n{tb}')\n",
        "        return f'âŒ Training failed to start:\\n```\\n{tb}\\n```', gr.update()\n",
        "\n",
        "\n",
        "def poll_training():\n",
        "    global training_proc, training_log\n",
        "\n",
        "    _state = sys.modules['__main__'].__dict__.get('state') or globals().get('state') or {}\n",
        "\n",
        "    if not training_log:\n",
        "        if training_proc is None:\n",
        "            return 'â³ Press \"Start training\" first.', '', ''\n",
        "        return 'â³ Waiting for first output...', '', ''\n",
        "\n",
        "    recent = '\\n'.join(training_log[-30:])\n",
        "\n",
        "    # Parse last iteration and loss\n",
        "    last_iter = 0\n",
        "    last_loss = 'n/a'\n",
        "    for line in reversed(training_log):\n",
        "        m = re.search(r'iteration\\s+(\\d+)', line, re.I)\n",
        "        if m:\n",
        "            last_iter = int(m.group(1))\n",
        "        m2 = re.search(r'loss[\\s:=]+([0-9.eE+\\-]+)', line, re.I)\n",
        "        if m2:\n",
        "            last_loss = m2.group(1)\n",
        "        if last_iter:\n",
        "            break\n",
        "\n",
        "    total_iters = _state.get('training_iterations', 15000)\n",
        "    pct = '{:.1f}%'.format(last_iter / total_iters * 100) if total_iters else ''\n",
        "    done = training_proc is not None and training_proc.poll() is not None\n",
        "    prefix = 'âœ… Done' if done else 'â³ Training'\n",
        "    status = '{} â€” iter {:,}/{:,} ({}) | loss={}'.format(prefix, last_iter, total_iters, pct, last_loss)\n",
        "\n",
        "    return status, recent, ''\n",
        "\n",
        "\n",
        "with gr.Blocks(title='Vid2Splat â€” Training') as train_ui:\n",
        "    gr.Markdown('### ğŸ§  3D Gaussian Splatting Training\\n'\n",
        "                '> `sh_degree` is always **3** â€” hardcoded for Unity VR Viewer compatibility.')\n",
        "    with gr.Row():\n",
        "        t_preset = gr.Dropdown(['Quick Preview', 'Balanced', 'High Quality', 'Custom'],\n",
        "                                label='Preset', value='Balanced')\n",
        "        t_iters  = gr.Slider(1000, 30000, value=15000, step=1000, label='Iterations (Custom)')\n",
        "        t_res    = gr.Dropdown([1, 2, 4], label='Resolution divisor (Custom)', value=2)\n",
        "\n",
        "    with gr.Accordion('Advanced hyperparameters', open=False):\n",
        "        adv_chk     = gr.Checkbox(label='Use custom values below', value=False)\n",
        "        t_dens_util = gr.Slider(1000, 30000, value=12000, step=500, label='densify_until_iter')\n",
        "        t_dens_int  = gr.Slider(50, 500, value=100, step=50, label='densification_interval')\n",
        "        t_lr_init   = gr.Number(value=0.00016, label='position_lr_init')\n",
        "        t_lr_final  = gr.Number(value=0.0000016, label='position_lr_final')\n",
        "        t_op_lr     = gr.Number(value=0.05, label='opacity_lr')\n",
        "        t_sc_lr     = gr.Number(value=0.005, label='scaling_lr')\n",
        "        t_dssim     = gr.Slider(0.0, 1.0, value=0.2, step=0.05, label='lambda_dssim')\n",
        "\n",
        "    train_btn  = gr.Button('Start training', variant='primary')\n",
        "    poll_btn   = gr.Button('Refresh progress')\n",
        "    t_status   = gr.Markdown()\n",
        "    t_log      = gr.Textbox(label='Training log (last 30 lines)', lines=15, interactive=False)\n",
        "    t_dummy    = gr.Textbox(visible=False)\n",
        "\n",
        "    train_btn.click(start_training,\n",
        "                    inputs=[t_preset, t_iters, t_res, adv_chk,\n",
        "                            t_dens_util, t_dens_int, t_lr_init, t_lr_final,\n",
        "                            t_op_lr, t_sc_lr, t_dssim],\n",
        "                    outputs=[t_status, t_dummy])\n",
        "    poll_btn.click(poll_training, outputs=[t_status, t_log, t_dummy])\n",
        "\n",
        "train_ui.launch(debug=False, share=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cde4dec",
      "metadata": {
        "id": "3cde4dec"
      },
      "source": [
        "## Section 6 â€” Results, Validation & Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "93027e0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "93027e0a",
        "outputId": "448426b5-c75a-4b90-e0f7-dba2fe2e5deb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://e0c13b9e5dca8c3bb6.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://e0c13b9e5dca8c3bb6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# â”€â”€ 6. Results, validation, download & preview â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import gradio as gr\n",
        "import struct, zipfile, os, shutil\n",
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "REQUIRED_FIELDS = (\n",
        "    ['x','y','z','nx','ny','nz','f_dc_0','f_dc_1','f_dc_2'] +\n",
        "    [f'f_rest_{i}' for i in range(45)] +\n",
        "    ['opacity','scale_0','scale_1','scale_2','rot_0','rot_1','rot_2','rot_3']\n",
        ")  # 62 fields\n",
        "\n",
        "\n",
        "def find_ply():\n",
        "    out = state.get('output_dir')\n",
        "    iters = state.get('training_iterations', 30000)\n",
        "    if not out:\n",
        "        return None\n",
        "    exact = Path(out) / 'point_cloud' / f'iteration_{iters}' / 'point_cloud.ply'\n",
        "    if exact.exists():\n",
        "        return exact\n",
        "    pc_root = Path(out) / 'point_cloud'\n",
        "    if pc_root.exists():\n",
        "        candidates = sorted(pc_root.glob('iteration_*/point_cloud.ply'))\n",
        "        if candidates:\n",
        "            return candidates[-1]\n",
        "    return None\n",
        "\n",
        "\n",
        "def validate_ply_file(ply_path):\n",
        "    if not ply_path or not Path(ply_path).exists():\n",
        "        return {}\n",
        "    fields, n_gauss = [], 0\n",
        "    is_ble = False\n",
        "    with open(ply_path, 'rb') as f:\n",
        "        for _ in range(200):\n",
        "            line = f.readline().decode('ascii','replace').strip()\n",
        "            if 'binary_little_endian' in line:\n",
        "                is_ble = True\n",
        "            if line.startswith('element vertex'):\n",
        "                try:\n",
        "                    n_gauss = int(line.split()[-1])\n",
        "                except ValueError:\n",
        "                    pass\n",
        "            if line.startswith('property float'):\n",
        "                fields.append(line.split()[-1])\n",
        "            if line == 'end_header':\n",
        "                break\n",
        "    missing = [f for f in REQUIRED_FIELDS if f not in fields]\n",
        "    size_mb = Path(ply_path).stat().st_size / 1024**2\n",
        "    return dict(n_gaussians=n_gauss, size_mb=size_mb,\n",
        "                is_ble=is_ble, missing=missing,\n",
        "                passed=(n_gauss > 0 and is_ble and not missing and size_mb > 0.5))\n",
        "\n",
        "\n",
        "def build_report():\n",
        "    ply = find_ply()\n",
        "    if not ply:\n",
        "        return 'âš  No PLY found â€” run training first.', None, None\n",
        "\n",
        "    v = validate_ply_file(str(ply))\n",
        "    if v.get('passed'):\n",
        "        status = (f'âœ… **PLY validation passed**\\n'\n",
        "                  f'- Gaussians: {v[\"n_gaussians\"]:,}\\n'\n",
        "                  f'- File size: {v[\"size_mb\"]:.1f} MB\\n'\n",
        "                  f'- Format: binary_little_endian âœ“\\n'\n",
        "                  f'- All 62 vertex fields present âœ“')\n",
        "    else:\n",
        "        issues = []\n",
        "        if not v.get('is_ble'): issues.append('Not binary_little_endian')\n",
        "        if v.get('missing'):    issues.append(f'Missing fields: {v[\"missing\"]}')\n",
        "        if v.get('size_mb',0) < 0.5: issues.append('File too small')\n",
        "        status = 'âš  PLY issues:\\n' + '\\n'.join(f'- {i}' for i in issues)\n",
        "\n",
        "    # â”€â”€ Quick scatter preview of Gaussian centres â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    try:\n",
        "        from plyfile import PlyData\n",
        "        pdata = PlyData.read(str(ply))\n",
        "        verts = pdata['vertex']\n",
        "        n = min(10000, len(verts))\n",
        "        idx = np.random.choice(len(verts), n, replace=False)\n",
        "        xs = np.array(verts['x'][idx], dtype=float)\n",
        "        ys = np.array(verts['y'][idx], dtype=float)\n",
        "        zs = np.array(verts['z'][idx], dtype=float)\n",
        "        opacities = 1 / (1 + np.exp(-np.array(verts['opacity'][idx], dtype=float)))\n",
        "        fig = go.Figure(data=[go.Scatter3d(\n",
        "            x=xs, y=ys, z=zs,\n",
        "            mode='markers',\n",
        "            marker=dict(size=1.5,\n",
        "                        color=opacities,\n",
        "                        colorscale='Viridis',\n",
        "                        opacity=0.6),\n",
        "        )])\n",
        "        fig.update_layout(title=f'{n:,} Gaussians (sample preview)',\n",
        "                          scene=dict(aspectmode='data'),\n",
        "                          margin=dict(l=0,r=0,t=30,b=0))\n",
        "    except Exception as e:\n",
        "        fig = None\n",
        "        print('Preview skipped:', e)\n",
        "\n",
        "    # â”€â”€ Zip for download â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    zip_path = Path(state.get('output_dir', '/content')) / 'point_cloud.zip'\n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "        zf.write(ply, 'point_cloud.ply')\n",
        "    state['zip_path'] = str(zip_path)\n",
        "\n",
        "    return status, fig, str(zip_path)\n",
        "\n",
        "\n",
        "with gr.Blocks(title='Vid2Splat â€” Results') as results_ui:\n",
        "    gr.Markdown('### ğŸ“¦ Results, Validation & Export')\n",
        "    report_btn  = gr.Button('Generate report & preview', variant='primary')\n",
        "    r_status    = gr.Markdown()\n",
        "    r_plot      = gr.Plot(label='3D Gaussian preview (sample)')\n",
        "    r_download  = gr.File(label='Download point_cloud.zip')\n",
        "    report_btn.click(build_report, outputs=[r_status, r_plot, r_download])\n",
        "\n",
        "    gr.Markdown('''\n",
        "---\n",
        "### ğŸ® Loading in the Unity VR Viewer\n",
        "1. Copy `point_cloud.ply` (from the zip) to the Unity project folder.\n",
        "2. Open the Unity project in the **Unity Editor** on an **NVIDIA GPU machine**.\n",
        "3. Set `GaussianSplattingModel â†’ Model File Path` to the `.ply` file path.\n",
        "4. Press **Play**.\n",
        "\n",
        "> The `.ply` uses `sh_degree=3` and binary-little-endian format â€” fully compatible with the `GaussianSplattingPlugin`.\n",
        "    ''')\n",
        "\n",
        "results_ui.launch(debug=False, share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeb648ac",
      "metadata": {
        "id": "aeb648ac"
      },
      "source": [
        "## (Optional) Save to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56eb7538",
      "metadata": {
        "id": "56eb7538",
        "outputId": "ee100ce6-cd55-4899-b469-548aad52d27a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "â„¹ SAVE_TO_DRIVE is False â€” skipping.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# â”€â”€ 7. (Optional) Save PLY to Google Drive â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "SAVE_TO_DRIVE = False   # â† set True to enable\n",
        "DRIVE_DEST    = 'MyDrive/Vid2Splat/'\n",
        "\n",
        "if SAVE_TO_DRIVE:\n",
        "    from google.colab import drive\n",
        "    import shutil\n",
        "    from pathlib import Path\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "    dest_dir = Path('/content/drive') / DRIVE_DEST\n",
        "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ply_zip = state.get('zip_path')\n",
        "    if ply_zip and Path(ply_zip).exists():\n",
        "        dst = dest_dir / Path(ply_zip).name\n",
        "        shutil.copy2(ply_zip, dst)\n",
        "        print(f'âœ… Saved to Drive: {dst}')\n",
        "    else:\n",
        "        print('âš  No zip found â€” run Section 6 first.')\n",
        "else:\n",
        "    print('â„¹ SAVE_TO_DRIVE is False â€” skipping.')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "G4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
